{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66bdf56e",
   "metadata": {},
   "source": [
    "# Upsert PDFs to qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7c0f28",
   "metadata": {},
   "source": [
    "#### **HOW IT WORKS**: It operate in PDF-wise fashion, unlike my previous notebooks that loaded and chunked an entire PDF in one go. This one loads and chunks PDFs one at a time to enable for checking the id and enabling some better error handling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee6ffdf",
   "metadata": {},
   "source": [
    "To upsert a single pdf:\n",
    "1. Set the qdrant collection name \n",
    "2. Choose local or cloud\n",
    "3. Run cells individually until you generate a pdf_id.\n",
    "4. Add the pdf medata into the spreadsheet\n",
    "5. Run the rest of the cells to upsert the pdf\n",
    "\n",
    "To upsert a folder of pdfs:\n",
    "1. Set the qdrant collection name \n",
    "2. Choose local or cloud\n",
    "3. Run the cells individually, stopping at `qdrant.add_documents(chunks)`. This initialize all the functions and config variables needed for the batch process. Yes, you will need to specify a specific PDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c1f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -qU pip\n",
    "# %pip install -qU langchain-openai openai langchain-community langchain-qdrant qdrant-client pympler pypdf==5.0.1\n",
    "\n",
    "# %pip install git+https://github.com/pikepdf/pikepdf.git#egg=pikepdf this requies python>=3.9\n",
    "# %pip install gspread google-auth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bda072",
   "metadata": {},
   "source": [
    "## 0. Imports and Configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed9776c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/drew_wilkins/Drews_Files/Drew/Python/Repositories/uscgaux/.venv-main/bin/python\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Confirm correct interpreter is used\n",
    "print(sys.executable)\n",
    "\n",
    "# Add parent directory to sys.path to import modules from a subdirectory\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import library_utils as lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b790f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_PATH = \"/Users/drew_wilkins/Drews_Files/Drew/Python/Localcode/.env\"\n",
    "load_dotenv(ENV_PATH)\n",
    "\n",
    "# Config LangSmith observability\n",
    "# LANGCHAIN_API_KEY = os.environ[\"LANGCHAIN_API_KEY\"]\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = \"ASK_main_upsert_notebook\"\n",
    "\n",
    "\n",
    "# Config Qdrant\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "# QDRANT_URL = st.secrets[\"QDRANT_URL\"]\n",
    "# QDRANT_API_KEY = st.secrets[\"QDRANT_API_KEY\"]\n",
    "QDRANT_PATH = \"./qdrant_db\"\n",
    "\n",
    "\n",
    "# Config langchain_openai\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY_ASK\")\n",
    "# OPENAI_API_KEY = st.secrets[\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "# Misc configs for tracing\n",
    "CONFIG = {\n",
    "    \"splitter_type\": \"CharacterTextSplitter\",\n",
    "    \"chunk_size\": 2000,\n",
    "    \"chunk_overlap\": 200,\n",
    "    \"length_function\": len,\n",
    "    \"separators\": [\"}\"],  # [\" \", \",\", \"\\n\"]\n",
    "    \"qdrant_collection_name\": \"ASK_vectorstore\",\n",
    "    \"embedding_model\": \"text-embedding-ada-002\",  # alt: text-embedding-3-large\n",
    "    \"embedding_dims\": 1536,  # alt: 1024\n",
    "    \"vector_name\": \"text-dense\",\n",
    "    \"sparse_vector_name\": \"None\",\n",
    "    \"sparse_embedding\": \"None\",\n",
    "    \"search_type\": \"mmr\",\n",
    "    \"k\": 5,\n",
    "    'fetch_k': 20,   # fetch 30 docs then select 5\n",
    "    'lambda_mult': .7,    # 0= max diversity, 1 is min. default is 0.5\n",
    "    \"score_threshold\": 0.5,\n",
    "    \"generation_model\": \"gpt-3.5-turbo-16k\",\n",
    "    \"temperature\": 0.7,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e82ee0",
   "metadata": {},
   "source": [
    "## 1. Initialize the Qdrant and LC Vectorstore objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61a90112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qdrant location: cloud\n",
      "\n",
      "Available collections:\n",
      "ASK_vectorstore\n",
      "ask_pdf_docs\n",
      "ASK_vectorstore-backup21APR2025\n",
      "ask_pdf_pages\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\n",
    "    url=QDRANT_URL,  # for cloud\n",
    "    api_key=QDRANT_API_KEY,  # for cloud\n",
    "    prefer_grpc=True,\n",
    "    # path=QDRANT_PATH,  # for local\n",
    ")\n",
    "\n",
    "\n",
    "lib.which_qdrant(client)\n",
    "lib.list_collections(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5148dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status=<CollectionStatus.GREEN: 'green'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=None indexed_vectors_count=10566 points_count=11615 segments_count=2 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=1536, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=True, datatype=None, multivector_config=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors={'text-sparse': SparseVectorParams(index=SparseIndexParams(full_scan_threshold=None, on_disk=False, datatype=None), modifier=None)}), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None, strict_mode_config=None) payload_schema={}\n"
     ]
    }
   ],
   "source": [
    "collection_info = client.get_collection(\n",
    "    collection_name=\"ASK_vectorstore\")\n",
    "print(collection_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "583113b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_qdrant.qdrant.QdrantVectorStore at 0x319329490>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "# Initialize a LangChain vectorstore object\n",
    "qdrant = QdrantVectorStore(client=client,\n",
    "                           collection_name=CONFIG[\"qdrant_collection_name\"],\n",
    "                           # embedding here is LC interface to the embedding model\n",
    "                           embedding=OpenAIEmbeddings(\n",
    "                               model=CONFIG[\"embedding_model\"]),\n",
    "                           validate_collection_config=True  # Skip validation\n",
    "                           )\n",
    "\n",
    "\n",
    "qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126f91a5",
   "metadata": {},
   "source": [
    "## 2. Specify the file locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b738407",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_filename = \"D7-SOP-AD-002_Proctor_Designation.pdf\"  #\n",
    "pdf_source_directory = \"./pdfs_backlog\"\n",
    "pdf_path = os.path.join(pdf_source_directory, pdf_filename)\n",
    "\n",
    "LIBRARY_CATALOG_ID = \"16F5tRIvuHncofRuXCsQ20A7utZWRuEgA2bvj4nQQjek\"\n",
    "\n",
    "PDF_LIVE_FOLDER_ID = \"1-vyQQp30mKzudkTOk7YJLmmVDirBOIpg\"\n",
    "PDF_BACKLOG_FOLDER_ID = \"1993TlUkd9_4XqWCutyY5oNTpmBdnxefc\"\n",
    "PDF_DELETED_FOLDER_ID = \"1FYUFxenYC6nWomzgv6j1O4394Zv6Bs5F\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3cc48d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
